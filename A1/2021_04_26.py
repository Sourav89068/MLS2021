# -*- coding: utf-8 -*-
"""2021_04_26.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sJzbwXTMV4B5AlC1C2zrYtKvxAgsb39K
"""

import torch

!git clone https://github.com/YoongiKim/CIFAR-10-images/

torch.cuda.is_available()

import torch
import torchvision
import numpy as np

# check if CUDA is available
train_on_gpu = torch.cuda.is_available()

if not train_on_gpu:
    print('CUDA is not available.  Training on CPU ...')
else:
    print('CUDA is available!  Training on GPU ...')

from torchvision import datasets
import torchvision.transforms as transforms
from torch.utils.data.sampler import SubsetRandomSampler

# number of subprocesses to use for data loading
num_workers = 0
# how many samples per batch to load
batch_size = 20
# percentage of training set to use as validation
valid_size = 0.2

# convert data to a normalized torch.FloatTensor
transform = transforms.Compose([
    transforms.RandomHorizontalFlip(), # randomly flip and rotate
    transforms.RandomRotation(10),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

# choose the training and test datasets
train_data = datasets.CIFAR10('data', train=True,
                              download=True, transform=transform)
test_data = datasets.CIFAR10('data', train=False,
                             download=True, transform=transform)

# obtain training indices that will be used for validation
num_train = len(train_data)
indices = list(range(num_train))
np.random.shuffle(indices)
split = int(np.floor(valid_size * num_train))
train_idx, valid_idx = indices[split:], indices[:split]

# define samplers for obtaining training and validation batches
train_sampler = SubsetRandomSampler(train_idx)
valid_sampler = SubsetRandomSampler(valid_idx)

# prepare data loaders (combine dataset and sampler)
train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,
    sampler=train_sampler, num_workers=num_workers)
valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, 
    sampler=valid_sampler, num_workers=num_workers)
test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, 
    num_workers=num_workers)

# specify the image classes
classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck']

import os
path=[]
classes=[]
for f_name in os.listdir("CIFAR-10-images/test/"):
  for files in os.listdir("CIFAR-10-images/test/"+f_name):
    pat='CIFAR-10-images/test/'+f_name+'/'+files
    clss=f_name
    path.append(pat)
    classes.append(clss)

import pandas as pd
test_data=pd.DataFrame({'path':p,'clss':c})

test_datacsv=test_data.to_csv("test.csv",index=False)





class MyDataset():
  def __init__(self,imageset,augment=True):
    with open(image_set,"r") as csv_handle:
      csv_reader=csv.reader(csv_handle,delimiter=",")
      self.imgfiles=[eachline[0] for eachline in csv_reader]
    with open(image_set,"r") as csv_handle:
      csv_reader=csv_reader(csv_handle,delimiter=",")
      self.classlabels=[int(eachline[1]) for eachline in csv_handle]
    self.augment=augment
  def __len__(self):
    return len(self.imgfiles)
  def __getitem__(self,idx):
    img=imageio.imread(self.imgfiles[idx])
    X=np.asarray(img,dtype=np.float32)
    if self.argument:
      X=do_your_transform(X)
    Y=self.classlabels[idx]
    return X,Y

